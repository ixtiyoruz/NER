{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "339a69c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import BertTokenizer, BertConfig, BertForTokenClassification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2408dfac",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f7b7321",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data= \"../data/annotated/cleaned_data.csv\"\n",
    "df = pd.read_csv(path_to_data)\n",
    "prod_start = 'B-PROD-STRT'\n",
    "prod_end = 'B-PROD-END'\n",
    "prod = 'B-PROD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a58f20cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>status</th>\n",
       "      <th>url</th>\n",
       "      <th>file_name</th>\n",
       "      <th>label</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Page Not Found The page you are looking for do...</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.vawayside.net/store/products/tag/beds</td>\n",
       "      <td>data/crawled_texts/idx_4_2_s_1.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>(07) 5556 0693 [email protected] 130 Siganto D...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://hemisphereliving.com.au/products/</td>\n",
       "      <td>data/crawled_texts/idx_0_4_s_1.json</td>\n",
       "      <td>[[187, 210, 'product'], [237, 267, 'product'],...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>404 We could not find the page you were lookin...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://edenliving.online/collections/summerlo...</td>\n",
       "      <td>data/crawled_texts/idx_1_4_s_0.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>404 Page not found Continue shopping</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.ourfurniturewarehouse.com.au/produ...</td>\n",
       "      <td>data/crawled_texts/idx_2_0_s_0.json</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>View fullsize image Email us about this produc...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.hudsonfurniture.com.au/products/st...</td>\n",
       "      <td>data/crawled_texts/idx_3_1_s_1.json</td>\n",
       "      <td>[[98, 123, 'product'], [590, 617, 'product'], ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                               text  status  \\\n",
       "0   1  Page Not Found The page you are looking for do...       1   \n",
       "1   2  (07) 5556 0693 [email protected] 130 Siganto D...       1   \n",
       "2   3  404 We could not find the page you were lookin...       0   \n",
       "3   4               404 Page not found Continue shopping       0   \n",
       "4   5  View fullsize image Email us about this produc...       1   \n",
       "\n",
       "                                                 url  \\\n",
       "0   http://www.vawayside.net/store/products/tag/beds   \n",
       "1          https://hemisphereliving.com.au/products/   \n",
       "2  https://edenliving.online/collections/summerlo...   \n",
       "3  https://www.ourfurniturewarehouse.com.au/produ...   \n",
       "4  https://www.hudsonfurniture.com.au/products/st...   \n",
       "\n",
       "                             file_name  \\\n",
       "0  data/crawled_texts/idx_4_2_s_1.json   \n",
       "1  data/crawled_texts/idx_0_4_s_1.json   \n",
       "2  data/crawled_texts/idx_1_4_s_0.json   \n",
       "3  data/crawled_texts/idx_2_0_s_0.json   \n",
       "4  data/crawled_texts/idx_3_1_s_1.json   \n",
       "\n",
       "                                               label Comments  \n",
       "0                                                 []       []  \n",
       "1  [[187, 210, 'product'], [237, 267, 'product'],...       []  \n",
       "2                                                 []       []  \n",
       "3                                                 []       []  \n",
       "4  [[98, 123, 'product'], [590, 617, 'product'], ...       []  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eba8fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the count of labels\n",
    "anno_counts = df.label.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2804926f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from torch import cuda\n",
    "device = 'cuda' if cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d17a8da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_labels(x):\n",
    "    text, labels =x['text'], eval(x['label'])\n",
    "    if len(labels) == 0:\n",
    "        return text, \",\".join([\"O\"]*len(text.split()))\n",
    "    last_index = 0\n",
    "    results = []\n",
    "    for label in labels:\n",
    "        start, end, l = label\n",
    "        before_words = text[last_index: start].split(\" \")\n",
    "        before_words = [word for word in before_words if len(word) > 0]\n",
    "        num_of_words_before = len(before_words)\n",
    "        \n",
    "        between_words = text[start: end].split(\" \")\n",
    "        between_words = [word for word in between_words if len(word) > 0]\n",
    "        num_of_words_between = len(between_words)\n",
    "        results.extend([\"O\"]*num_of_words_before)\n",
    "#         product_label = [prod_start] + ['O'] * (num_of_words_between-2) \n",
    "#         if num_of_words_between > 1:\n",
    "#             product_label += [prod_end]\n",
    "        product_label = [prod]*num_of_words_between\n",
    "        results.extend(product_label)\n",
    "        last_index = end\n",
    "    last_words = text[last_index:].split(\" \")\n",
    "    last_words = [word for word in last_words if len(word) > 0]\n",
    "    results.extend([\"O\"] * len(last_words))\n",
    "    \n",
    "    return text, \",\".join(results)\n",
    "df = pd.read_csv(path_to_data)\n",
    "df[['text', 'label']] = df.apply(lambda x: pd.Series([transform_labels(x)[0], transform_labels(x)[1]]), axis=1)\n",
    "final_df = df[['text', 'label']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac22b573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Page Not Found The page you are looking for do...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(07) 5556 0693 [email protected] 130 Siganto D...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>404 We could not find the page you were lookin...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>404 Page not found Continue shopping</td>\n",
       "      <td>O,O,O,O,O,O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>View fullsize image Email us about this produc...</td>\n",
       "      <td>O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-PROD,B-PROD,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Page Not Found The page you are looking for do...   \n",
       "1  (07) 5556 0693 [email protected] 130 Siganto D...   \n",
       "2  404 We could not find the page you were lookin...   \n",
       "3               404 Page not found Continue shopping   \n",
       "4  View fullsize image Email us about this produc...   \n",
       "\n",
       "                                               label  \n",
       "0                O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O  \n",
       "1  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "2  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,...  \n",
       "3                                        O,O,O,O,O,O  \n",
       "4  O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,O,B-PROD,B-PROD,...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fae4da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5933985",
   "metadata": {},
   "source": [
    "## check the class imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "617277af",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = final_df.apply(lambda x:len([ label for label in x['label'].split(\",\") if not label == 'O']), axis=1)\n",
    "final_df = final_df[counts>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2d1d3d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 129)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts[counts>0]), len(counts[counts==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c059d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d86d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_preserve_labels(sentence, text_labels, tokenizer):\n",
    "    \"\"\"\n",
    "    Word piece tokenization makes it difficult to match word labels\n",
    "    back up with individual word pieces. This function tokenizes each\n",
    "    word one at a time so that it is easier to preserve the correct\n",
    "    label for each subword. It is, of course, a bit slower in processing\n",
    "    time, but it will help our model achieve higher accuracy.\n",
    "    \"\"\"\n",
    "    labels = text_labels.split(\",\")\n",
    "    words = sentence.split()\n",
    "    tokenized_sentence = []\n",
    "    processed_labels = []\n",
    "    for word, label in zip(words, labels):\n",
    "        \n",
    "        # Tokenize the word and count # of subwords the word is broken into\n",
    "        tokenized_word = tokenizer.tokenize(word)\n",
    "        n_subwords = len(tokenized_word)\n",
    "\n",
    "        # Add the tokenized word to the final tokenized word list\n",
    "        tokenized_sentence.extend(tokenized_word)\n",
    "\n",
    "        # Add the same label to the new list of labels `n_subwords` times\n",
    "        processed_labels.extend([label] * n_subwords)\n",
    "\n",
    "    return tokenized_sentence, processed_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "282702cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize_and_preserve_labels(final_df.iloc[1,0], final_df.iloc[1,1], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9bb939a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataset(Dataset):\n",
    "    def __init__(self, dataframe, tokenizer, max_len):\n",
    "        self.len = len(dataframe)\n",
    "        self.data = dataframe\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        # step 1: tokenize (and adapt corresponding labels)\n",
    "        sentence = self.data.text[index]  \n",
    "        word_labels = self.data.label[index]  \n",
    "        tokenized_sentence, labels = tokenize_and_preserve_labels(sentence, word_labels, self.tokenizer)\n",
    "        \n",
    "        # step 2: add special tokens (and corresponding labels)\n",
    "        tokenized_sentence = [\"[CLS]\"] + tokenized_sentence + [\"[SEP]\"] # add special tokens\n",
    "        labels.insert(0, \"O\") # add outside label for [CLS] token\n",
    "        labels.insert(-1, \"O\") # add outside label for [SEP] token\n",
    "\n",
    "        # step 3: truncating/padding\n",
    "        maxlen = self.max_len\n",
    "\n",
    "        if (len(tokenized_sentence) > maxlen):\n",
    "          # truncate\n",
    "          tokenized_sentence = tokenized_sentence[:maxlen]\n",
    "          labels = labels[:maxlen]\n",
    "        else:\n",
    "          # pad\n",
    "          tokenized_sentence = tokenized_sentence + ['[PAD]'for _ in range(maxlen - len(tokenized_sentence))]\n",
    "          labels = labels + [\"O\" for _ in range(maxlen - len(labels))]\n",
    "\n",
    "        # step 4: obtain the attention mask\n",
    "        attn_mask = [1 if tok != '[PAD]' else 0 for tok in tokenized_sentence]\n",
    "        \n",
    "        # step 5: convert tokens to input ids\n",
    "        ids = self.tokenizer.convert_tokens_to_ids(tokenized_sentence)\n",
    "\n",
    "        label_ids = [label2id[label] for label in labels]\n",
    "        # the following line is deprecated\n",
    "        #label_ids = [label if label != 0 else -100 for label in label_ids]\n",
    "        \n",
    "        return {\n",
    "              'ids': torch.tensor(ids, dtype=torch.long),\n",
    "              'mask': torch.tensor(attn_mask, dtype=torch.long),\n",
    "              #'token_type_ids': torch.tensor(token_ids, dtype=torch.long),\n",
    "              'targets': torch.tensor(label_ids, dtype=torch.long)\n",
    "        } \n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb658819",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 128\n",
    "label2id = {'O':0, prod:1}#, prod_start:2, prod_end:3}\n",
    "id2label = {0:'O', 1:prod}#, 2:prod_start, 3:prod_end}\n",
    "TRAIN_BATCH_SIZE = 8\n",
    "VALID_BATCH_SIZE = 2\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = 5e-06\n",
    "MAX_GRAD_NORM = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7b3294",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4369bc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "train_dataset = final_df.sample(frac=train_size,random_state=200)\n",
    "test_dataset = final_df.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "befeeee5",
   "metadata": {},
   "source": [
    "## try to unbalance the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f04cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = train_dataset.apply(lambda x:len([ label for label in x['label'].split(\",\") if not label == 'O']), axis=1)\n",
    "train_dataset = pd.concat([train_dataset]+[train_dataset[counts>3]]*2)\n",
    "\n",
    "counts = test_dataset.apply(lambda x:len([ label for label in x['label'].split(\",\") if not label == 'O']), axis=1)\n",
    "test_dataset = pd.concat([test_dataset] +[test_dataset[counts>3]]*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61f05ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.reset_index(drop=True)\n",
    "test_dataset = test_dataset.reset_index(drop=True)\n",
    "training_set = dataset(train_dataset, tokenizer, MAX_LEN)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa31dccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
    "                'shuffle': True,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
    "                'shuffle': False,\n",
    "                'num_workers': 0\n",
    "                }\n",
    "\n",
    "training_loader = DataLoader(training_set, **train_params)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4d2f9ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForTokenClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForTokenClassification.from_pretrained('bert-base-uncased', \n",
    "                                                   num_labels=len(id2label),\n",
    "                                                   id2label=id2label,\n",
    "                                                   label2id=label2id)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3fd9c35f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6491, device='cuda:0', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = training_set[0][\"ids\"].unsqueeze(0)\n",
    "mask = training_set[0][\"mask\"].unsqueeze(0)\n",
    "targets = training_set[0][\"targets\"].unsqueeze(0)\n",
    "ids = ids.to(device)\n",
    "mask = mask.to(device)\n",
    "targets = targets.to(device)\n",
    "outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "initial_loss = outputs[0]\n",
    "initial_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b3ea0ab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_logits = outputs[1]\n",
    "tr_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3c86f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f79ffa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(params=model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bb5da1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the training function on the 80% of the dataset for tuning the bert model\n",
    "def train(epoch):\n",
    "    tr_loss, tr_accuracy = 0, 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    tr_preds, tr_labels = [], []\n",
    "    # put model in training mode\n",
    "    model.train()    \n",
    "    for idx, batch in enumerate(training_loader):        \n",
    "        ids = batch['ids'].to(device, dtype = torch.long)\n",
    "        mask = batch['mask'].to(device, dtype = torch.long)\n",
    "        targets = batch['targets'].to(device, dtype = torch.long)\n",
    "\n",
    "        outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "        loss, tr_logits = outputs.loss, outputs.logits\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        nb_tr_steps += 1\n",
    "        nb_tr_examples += targets.size(0)\n",
    "        \n",
    "        if idx % 100==0:\n",
    "            loss_step = tr_loss/nb_tr_steps\n",
    "            print(f\"Training loss per 100 training steps: {loss_step}\")\n",
    "           \n",
    "        # compute training accuracy\n",
    "        flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "        active_logits = tr_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "        flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "        # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "        active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "        targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "        predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "        \n",
    "        tr_preds.extend(predictions)\n",
    "        tr_labels.extend(targets)\n",
    "        \n",
    "        tmp_tr_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "        tr_accuracy += tmp_tr_accuracy\n",
    "    \n",
    "        # gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(\n",
    "            parameters=model.parameters(), max_norm=MAX_GRAD_NORM\n",
    "        )\n",
    "        \n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = tr_loss / nb_tr_steps\n",
    "    tr_accuracy = tr_accuracy / nb_tr_steps\n",
    "    print(f\"Training loss epoch: {epoch_loss}\")\n",
    "    print(f\"Training accuracy epoch: {tr_accuracy}\")\n",
    "    \n",
    "\n",
    "def valid(model, testing_loader):\n",
    "    # put model in evaluation mode\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss, eval_accuracy = 0, 0\n",
    "    nb_eval_examples, nb_eval_steps = 0, 0\n",
    "    eval_preds, eval_labels = [], []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for idx, batch in enumerate(testing_loader):\n",
    "            \n",
    "            ids = batch['ids'].to(device, dtype = torch.long)\n",
    "            mask = batch['mask'].to(device, dtype = torch.long)\n",
    "            targets = batch['targets'].to(device, dtype = torch.long)\n",
    "            \n",
    "            outputs = model(input_ids=ids, attention_mask=mask, labels=targets)\n",
    "            loss, eval_logits = outputs.loss, outputs.logits\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "\n",
    "            nb_eval_steps += 1\n",
    "            nb_eval_examples += targets.size(0)\n",
    "        \n",
    "            if idx % 100==0:\n",
    "                loss_step = eval_loss/nb_eval_steps\n",
    "                print(f\"Validation loss per 100 evaluation steps: {loss_step}\")\n",
    "              \n",
    "            # compute evaluation accuracy\n",
    "            flattened_targets = targets.view(-1) # shape (batch_size * seq_len,)\n",
    "            active_logits = eval_logits.view(-1, model.num_labels) # shape (batch_size * seq_len, num_labels)\n",
    "            flattened_predictions = torch.argmax(active_logits, axis=1) # shape (batch_size * seq_len,)\n",
    "            # now, use mask to determine where we should compare predictions with targets (includes [CLS] and [SEP] token predictions)\n",
    "            active_accuracy = mask.view(-1) == 1 # active accuracy is also of shape (batch_size * seq_len,)\n",
    "            targets = torch.masked_select(flattened_targets, active_accuracy)\n",
    "            predictions = torch.masked_select(flattened_predictions, active_accuracy)\n",
    "            \n",
    "            eval_labels.extend(targets)\n",
    "            eval_preds.extend(predictions)\n",
    "            \n",
    "            tmp_eval_accuracy = accuracy_score(targets.cpu().numpy(), predictions.cpu().numpy())\n",
    "            eval_accuracy += tmp_eval_accuracy\n",
    "    \n",
    "    # print(eval_labels)\n",
    "    # print(eval_preds)\n",
    "\n",
    "    labels = [id2label[id.item()] for id in eval_labels]\n",
    "    predictions = [id2label[id.item()] for id in eval_preds]\n",
    "\n",
    "    # print(labels)\n",
    "    # print(predictions)\n",
    "    \n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    eval_accuracy = eval_accuracy / nb_eval_steps\n",
    "    print(f\"Validation Loss: {eval_loss}\")\n",
    "    print(f\"Validation Accuracy: {eval_accuracy}\")\n",
    "\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "673c8811",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training epoch: 1\n",
      "Training loss per 100 training steps: 0.6548482179641724\n",
      "Training loss epoch: 0.4086983702752901\n",
      "Training accuracy epoch: 0.8739295193498223\n",
      "Validation loss per 100 evaluation steps: 0.11200238764286041\n",
      "Validation Loss: 0.30482092251380283\n",
      "Validation Accuracy: 0.8974464529664326\n",
      "Training epoch: 2\n",
      "Training loss per 100 training steps: 0.31450915336608887\n",
      "Training loss epoch: 0.30360171522783197\n",
      "Training accuracy epoch: 0.8945084498988589\n",
      "Validation loss per 100 evaluation steps: 0.15789996087551117\n",
      "Validation Loss: 0.2713558315521195\n",
      "Validation Accuracy: 0.8974464529664326\n",
      "Training epoch: 3\n",
      "Training loss per 100 training steps: 0.16846996545791626\n",
      "Training loss epoch: 0.25842808381370874\n",
      "Training accuracy epoch: 0.8954363606916707\n",
      "Validation loss per 100 evaluation steps: 0.16674846410751343\n",
      "Validation Loss: 0.23733855216276079\n",
      "Validation Accuracy: 0.8974464529664326\n",
      "Training epoch: 4\n",
      "Training loss per 100 training steps: 0.25897252559661865\n",
      "Training loss epoch: 0.20643580478170645\n",
      "Training accuracy epoch: 0.9050665951507304\n",
      "Validation loss per 100 evaluation steps: 0.0989261269569397\n",
      "Validation Loss: 0.18706683211383365\n",
      "Validation Accuracy: 0.9227776151444184\n",
      "Training epoch: 5\n",
      "Training loss per 100 training steps: 0.17887361347675323\n",
      "Training loss epoch: 0.15581097907346228\n",
      "Training accuracy epoch: 0.9330690577056772\n",
      "Validation loss per 100 evaluation steps: 0.11263003945350647\n",
      "Validation Loss: 0.15836959225790842\n",
      "Validation Accuracy: 0.9369145199063231\n",
      "Training epoch: 6\n",
      "Training loss per 100 training steps: 0.11276159435510635\n",
      "Training loss epoch: 0.11679949741000714\n",
      "Training accuracy epoch: 0.9522934137646607\n",
      "Validation loss per 100 evaluation steps: 0.09213824570178986\n",
      "Validation Loss: 0.14517217129468918\n",
      "Validation Accuracy: 0.945099043715847\n",
      "Training epoch: 7\n",
      "Training loss per 100 training steps: 0.07812836021184921\n",
      "Training loss epoch: 0.09218221335955289\n",
      "Training accuracy epoch: 0.9632945289665638\n",
      "Validation loss per 100 evaluation steps: 0.11352244764566422\n",
      "Validation Loss: 0.151301073353915\n",
      "Validation Accuracy: 0.9516094603825136\n",
      "Training epoch: 8\n",
      "Training loss per 100 training steps: 0.1026885136961937\n",
      "Training loss epoch: 0.08223151107845099\n",
      "Training accuracy epoch: 0.9684109312709627\n",
      "Validation loss per 100 evaluation steps: 0.07641272246837616\n",
      "Validation Loss: 0.1574522237337771\n",
      "Validation Accuracy: 0.9491913056206089\n",
      "Training epoch: 9\n",
      "Training loss per 100 training steps: 0.06620628386735916\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining epoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     labels, predictions \u001b[38;5;241m=\u001b[39m valid(model, testing_loader)\n",
      "Cell \u001b[0;32mIn[23], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     13\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(input_ids\u001b[38;5;241m=\u001b[39mids, attention_mask\u001b[38;5;241m=\u001b[39mmask, labels\u001b[38;5;241m=\u001b[39mtargets)\n\u001b[1;32m     14\u001b[0m loss, tr_logits \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss, outputs\u001b[38;5;241m.\u001b[39mlogits\n\u001b[0;32m---> 15\u001b[0m tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m nb_tr_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     18\u001b[0m nb_tr_examples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Training epoch: {epoch + 1}\")\n",
    "    train(epoch)\n",
    "    labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003b72d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4e664004",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = final_df.sample(frac=train_size,random_state=200)\n",
    "test_dataset = final_df.drop(train_dataset.index)\n",
    "\n",
    "test_dataset = test_dataset.reset_index(drop=True)\n",
    "testing_set = dataset(test_dataset, tokenizer, MAX_LEN)\n",
    "testing_loader = DataLoader(testing_set, **test_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4d0f7538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss per 100 evaluation steps: 0.12214331328868866\n",
      "Validation Loss: 0.1358772942589389\n",
      "Validation Accuracy: 0.9539290186703097\n"
     ]
    }
   ],
   "source": [
    "labels, predictions = valid(model, testing_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1f218a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        PROD       0.73      0.73      0.73       198\n",
      "\n",
      "   micro avg       0.73      0.73      0.73       198\n",
      "   macro avg       0.73      0.73      0.73       198\n",
      "weighted avg       0.73      0.73      0.73       198\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "print(classification_report([labels], [predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c37bd6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(classification_report([labels], [predictions]))\n",
    "# labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6056dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/saved_models/bert_trained.pth\"\n",
    "torch.save(model, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "35ae73a1",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS]       O\n",
      "can         O\n",
      "we          O\n",
      "help        O\n",
      "?           O\n",
      "08          O\n",
      "83          O\n",
      "##9         O\n",
      "##9         O\n",
      "125         O\n",
      "##0         O\n",
      "furniture   O\n",
      "home        O\n",
      "##ware      O\n",
      "##s         O\n",
      "mari        O\n",
      "##me        O\n",
      "##kko       O\n",
      "look        O\n",
      "##books     O\n",
      "logo        O\n",
      "0           O\n",
      "your        O\n",
      "browser     O\n",
      "does        O\n",
      "not         O\n",
      "support     O\n",
      "the         O\n",
      "video       O\n",
      "tag         O\n",
      ".           O\n",
      "share       O\n",
      "on          O\n",
      ":           O\n",
      "17          O\n",
      "reviews     O\n",
      "sore        B-PROD\n",
      "##nsen      B-PROD\n",
      "tea         B-PROD\n",
      "##k         B-PROD\n",
      "bench       B-PROD\n",
      "|           B-PROD\n",
      "100         B-PROD\n",
      "##cm        B-PROD\n",
      "$           O\n",
      "329         O\n",
      ".           O\n",
      "00          O\n",
      "add         O\n",
      "to          O\n",
      "cart        O\n",
      "payment     O\n",
      "options     O\n",
      "available   O\n",
      "or          O\n",
      "buy         O\n",
      "now         O\n",
      "from        O\n",
      "$           O\n",
      "13          O\n",
      ".           O\n",
      "71          O\n",
      "*           O\n",
      "per         O\n",
      "month       O\n",
      ".           O\n",
      "see         O\n",
      "more        O\n",
      "our         O\n",
      "signature   O\n",
      "solid       O\n",
      "tea         O\n",
      "##k         O\n",
      "bench       O\n",
      ",           O\n",
      "exclusive   O\n",
      "for         O\n",
      "living      O\n",
      "by          O\n",
      "design      O\n",
      "in          O\n",
      "australia   O\n",
      ".           O\n",
      "as          O\n",
      "featured    O\n",
      "on          O\n",
      "the         O\n",
      "front       O\n",
      "cover       O\n",
      "of          O\n",
      "country     O\n",
      "style       O\n",
      "magazine    O\n",
      ",           O\n",
      "along       O\n",
      "with        O\n",
      "house       O\n",
      "and         O\n",
      "garden      O\n",
      "editorial   O\n"
     ]
    }
   ],
   "source": [
    "idx= np.random.randint(100)\n",
    "# print the first 30 tokens and corresponding labels\n",
    "for token, label in zip(tokenizer.convert_ids_to_tokens(training_set[idx][\"ids\"][:100]), training_set[idx][\"targets\"][:100]):\n",
    "  print('{0:10}  {1}'.format(token, id2label[label.item()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae20fff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
